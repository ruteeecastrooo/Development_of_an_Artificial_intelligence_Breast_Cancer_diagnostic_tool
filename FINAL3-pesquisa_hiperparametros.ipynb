{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necessárias\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "var = 'f-value'\n",
    "# var = 'pca'\n",
    "# var = total\n",
    "# Ler os dados para treino, validação e teste\n",
    "# Neste caso, estamos a usar os dados que foram pré-processados utilizando o critério 'f-value' para seleção de características na pipeline feature_selection.\n",
    "\n",
    "with open(f'X_train_validation_{var}.pkl','rb') as f:\n",
    "    X_train_validation = pickle.load(f)\n",
    "with open(f'y_train_validation_{var}.pkl','rb') as f:\n",
    "    y_train_validation = pickle.load(f)\n",
    "with open(f'X_test_{var}.pkl','rb') as f:\n",
    "    X_test = pickle.load(f)\n",
    "with open(f'y_test_{var}.pkl','rb') as f:\n",
    "    y_test = pickle.load(f)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\"\"\"\n",
    "Classe CustomRandomizedSearchCV:\n",
    "A CustomRandomizedSearchCV é uma adaptação do RandomizedSearchCV providenciado pelo Scikit-learn.\n",
    "Ela foi projetada com a intenção de simplificar e potencializar a busca aleatória de hiperparâmetros em diversos modelos de aprendizado de máquina. \n",
    "A classe foi desenvolvida para permitir uma avaliação simultânea e comparativa de diferentes modelos e as combinações de seus hiperparâmetros.\n",
    "\n",
    "Ao concluir a pesquisa, a classe proporciona uma análise detalhada, revelando os hiperparâmetros mais eficazes para cada modelo avaliado.\n",
    "Além disso, apresenta o best score de cada modelo baseando-se na métrica F1 micro-averaged.\n",
    "\n",
    "Desta forma, otimiza-se o processo de seleção e ajuste de modelo, garantindo que os melhores hiperparâmetros\n",
    "sejam identificados de maneira eficiente e sistemática.\n",
    "\"\"\"\n",
    "\n",
    "class CustomRandomizedSearchCV:\n",
    "    \n",
    "    def __init__(self, X, y, algorithm, parameter_distribution, cv_folds = 10, num_iters_allowed=100, score_function='f1_micro', n_jobs=25) -> None:\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.algorithm = algorithm\n",
    "        self.parameter_distribution = parameter_distribution\n",
    "        self.cv_folds = cv_folds\n",
    "        self.num_iters_allowed = num_iters_allowed\n",
    "        self.score_function = score_function\n",
    "        self.search = None\n",
    "        self.n_jobs = n_jobs\n",
    "        \n",
    "    # Calcula o total de combinações de parâmetros possíveis\n",
    "    def calc_total_parameters(self, params_list: list) -> int: \n",
    "        tmp = [len(lista) for lista in params_list.values()]\n",
    "        res = 1\n",
    "        for x in tmp:\n",
    "            res *= x\n",
    "        return res\n",
    "    \n",
    "    # Executa RandomizedSearchCV\n",
    "    def random_search_cv(self):\n",
    "        if self.search == None:\n",
    "            percentage = float(self.num_iters_allowed) * 100 / self.calc_total_parameters(self.parameter_distribution)\n",
    "            print(f\"Going to train and test {self.num_iters_allowed} out of a total of {self.calc_total_parameters(self.parameter_distribution)} parameter combinations ({percentage:.2f}%)\")\n",
    "            random_search_cv = RandomizedSearchCV(self.algorithm, self.parameter_distribution, random_state=0, n_iter=self.num_iters_allowed, cv=self.cv_folds, n_jobs=self.n_jobs, scoring=self.score_function)\n",
    "            self.search = random_search_cv.fit(self.X, self.y)\n",
    "    \n",
    "    # Retorna os melhores parâmetros encontrados\n",
    "    def get_best_parameters(self):\n",
    "        self.random_search_cv()\n",
    "        return self.search.best_params_\n",
    "    \n",
    "    def get_best_score(self):\n",
    "        self.random_search_cv()\n",
    "        return self.search.best_score_\n",
    "    \n",
    "    def get_average_train_time(self):\n",
    "        self.random_search_cv()\n",
    "        return np.mean(self.search.cv_results_['mean_fit_time'])\n",
    "    \n",
    "    def get_average_test_time(self):\n",
    "        self.random_search_cv()\n",
    "        return np.mean(self.search.cv_results_['mean_score_time'])\n",
    "    \n",
    "    def get_best_estimator(self):\n",
    "        self.random_search_cv()\n",
    "        return self.search.best_estimator_\n",
    "    \n",
    "    def get_all_cv_results(self):\n",
    "        self.random_search_cv()\n",
    "        return self.search.cv_results_\n",
    "\n",
    "    def print_details(self):\n",
    "        print(f\"Best score: {self.get_best_score()}\")\n",
    "        print(f\"Best parameters: {self.get_best_parameters()}\")\n",
    "        print(f\"Average train time (secs): {self.get_average_train_time():.2}\")\n",
    "        print(f\"Average test time (secs): {self.get_average_test_time():.2}\")\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "# O algoritmo SVM é útil para encontrar fronteiras não lineares complexas em conjuntos de dados de alta dimensão.\n",
    "\n",
    "svm_random_search_cv = CustomRandomizedSearchCV(X_train_validation, y_train_validation, algorithm=SVC(class_weight='balanced'),\n",
    "                               parameter_distribution=dict(C=np.logspace(np.log10(0.1),np.log10(1000), 1000), \n",
    "                                                           kernel=['linear', 'poly', 'rbf'], \n",
    "                                                           gamma=np.logspace(np.log10(0.001),np.log10(10), 1000), \n",
    "                                                           max_iter=[100, 200, 500, 1000]),\n",
    "                               num_iters_allowed=1000)\n",
    "\n",
    "svm_random_search_cv.print_details()\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# KNN é um algoritmo de aprendizagem baseado em instância e é usado tanto para classificação quanto regressão.\n",
    "\n",
    "knn_random_search_cv = CustomRandomizedSearchCV(X_train_validation, y_train_validation, algorithm=KNeighborsClassifier(),\n",
    "                               parameter_distribution=dict(n_neighbors=[int(x) for x in np.linspace(1, 30, 30)], \n",
    "                                                           algorithm=['ball_tree', 'kd_tree', 'brute'],\n",
    "                                                           weights=['uniform', 'distance'], \n",
    "                                                           metric=['euclidean', 'manhattan', 'minkowski']), \n",
    "                               num_iters_allowed=1000)\n",
    "\n",
    "\n",
    "knn_random_search_cv.print_details()\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# A regressão logística é usada quando a variável dependente é categórica.\n",
    "\n",
    "log_reg_random_search_cv = CustomRandomizedSearchCV(X_train_validation, y_train_validation, algorithm=LogisticRegression(),\n",
    "                               parameter_distribution=dict(penalty=['l1', 'l2', 'elasticnet', 'none'],\n",
    "                                                           solver=['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                                                           max_iter=[100, 200, 500, 1000, 2000, 3500, 5000],\n",
    "                                                           multi_class=['auto', 'ovr', 'multinomial'],\n",
    "                                                           C=np.linspace(0.5, 2, 30)), \n",
    "                               num_iters_allowed=1000)\n",
    "\n",
    "\n",
    "log_reg_random_search_cv.print_details()\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# As árvores de decisão são usadas na tomada de decisões e para resolver problemas de classificação e regressão.\n",
    "\n",
    "dt_random_search_cv = CustomRandomizedSearchCV(X_train_validation, y_train_validation, algorithm=DecisionTreeClassifier(),\n",
    "                               parameter_distribution=dict(\n",
    "                               criterion=['gini', 'entropy'],\n",
    "                               splitter=['best', 'random'],\n",
    "                               max_depth=[None, 2, 4, 8, 16],\n",
    "                               min_samples_split=[2, 4, 8, 16, 32],\n",
    "                               # min_samples_leaf=[1],\n",
    "                               max_features=['auto', 'sqrt', 'log2'],\n",
    "                               ), \n",
    "                               num_iters_allowed=1000)\n",
    "\n",
    "\n",
    "dt_random_search_cv.print_details()\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Um random forest é um meta-estimador que se ajusta a uma série de árvores de decisão.\n",
    "\n",
    "rf_random_search_cv = CustomRandomizedSearchCV(X_train_validation, y_train_validation, algorithm=RandomForestClassifier(n_estimators=100),\n",
    "                               parameter_distribution=dict(\n",
    "                                   criterion=['gini', 'entropy'],\n",
    "                                    max_depth=[None, 2, 4, 8, 16],\n",
    "                                    min_samples_split=[2, 4, 8, 16, 32],\n",
    "                                    max_features=['auto', 'sqrt', 'log2'],\n",
    "                               ), \n",
    "                               num_iters_allowed=1000)\n",
    "\n",
    "rf_random_search_cv.print_details()\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# AdaBoost é um algoritmo de boosting\n",
    "\n",
    "ada_b_random_search_cv = CustomRandomizedSearchCV(X_train_validation, y_train_validation, algorithm=AdaBoostClassifier(),\n",
    "                               parameter_distribution=dict(algorithm=['SAMME', 'SAMME.R'],\n",
    "                                                           n_estimators=[10, 50, 100, 200],\n",
    "                                                           learning_rate= np.logspace(np.log10(0.01),np.log10(1), 100)\n",
    "                                                           \n",
    "                               ), \n",
    "                               num_iters_allowed=1000)\n",
    "\n",
    "\n",
    "ada_b_random_search_cv.print_details()\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# MLP é uma rede neural artificial que pode ser usada tanto para classificação quanto para regressão.\n",
    "\n",
    "mlp_single_layer_random_search_cv = CustomRandomizedSearchCV(X_train_validation, y_train_validation, algorithm=MLPClassifier(),\n",
    "                               parameter_distribution=dict(hidden_layer_sizes=[(128,),\n",
    "                                                                               (256,),\n",
    "                                                                               (512,),\n",
    "                                                                               (1024,),\n",
    "                                                                               (2048,)],\n",
    "                                                           solver=['lbfgs', 'sgd', 'adam'],\n",
    "                                                           learning_rate=['constant', 'invscaling', 'adaptive'],\n",
    "                                                           learning_rate_init=np.logspace(np.log10(0.001),np.log10(1), 1000),\n",
    "                                                           max_iter=[200, 500, 2000],\n",
    "                                                           batch_size=[\"auto\", 64, 512]\n",
    "                                                           ), \n",
    "                               num_iters_allowed=1000,\n",
    "                               )\n",
    "\n",
    "\n",
    "\n",
    "mlp_single_layer_random_search_cv.print_details()\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# algorithm = MLPClassifier()\n",
    "mlp_dnn_random_search_cv = CustomRandomizedSearchCV(X_train_validation, y_train_validation, algorithm=MLPClassifier(),\n",
    "                               parameter_distribution=dict(hidden_layer_sizes=[(512, 256, 128, 128, 128, 128, 128, 128),\n",
    "                                                                               (256, 128, 128, 128, 128, 128, 128, 128),\n",
    "                                                                               (512, 256, 128, 128, 128, 128, 128),\n",
    "                                                                               (512, 256, 128, 128, 128, 128),\n",
    "                                                                               (256, 128, 128, 128, 128), \n",
    "                                                                               (512, 128, 128, 128, 128), \n",
    "                                                                               (512, 128, 128, 128),\n",
    "                                                                               (256, 128, 128, 128),\n",
    "                                                                               (256, 128, 128), \n",
    "                                                                               (512, 128),\n",
    "                                                                               (256, 128)],\n",
    "                                                           solver=['lbfgs', 'sgd', 'adam'],\n",
    "                                                           learning_rate=['constant', 'invscaling', 'adaptive'],\n",
    "                                                           learning_rate_init=np.logspace(np.log10(0.001),np.log10(1), 1000),\n",
    "                                                           max_iter=[200, 500, 2000],\n",
    "                                                           batch_size=[\"auto\", 64, 512]\n",
    "                                                           ), \n",
    "                               num_iters_allowed=1000,\n",
    "                               )\n",
    "\n",
    "mlp_dnn_random_search_cv.print_details()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
